{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = np.load(\"X_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "person_test = np.load(\"person_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "# for i in range(2115):\n",
    "\n",
    "i=3\n",
    "plt.imshow(X_train_valid[i, :, :100])\n",
    "print(y_train_valid[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the best model till now. 3 conv, 1 FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        \"\"\"\n",
    "        We define a network based on the parameter to predict whether the slice is a seizure. The current models are:\n",
    "        - base: flatten the matrix and apply a neural net with one hidden layer\n",
    "        - conv: apply a standard vision neural net of 3 convolutional layers (filters, batch norm, pool, relu)\n",
    "                and then flatten and apply two fully connected layers with batch norm and dropout\n",
    "        - lstm: a\n",
    "\n",
    "        Args:\n",
    "            params: (Params) contains num_channels\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.type = params[\"type\"]\n",
    "\n",
    "        if self.type == \"reg\":\n",
    "            self.fc = nn.Linear(22 * 1000, 1)\n",
    "\n",
    "        if self.type == \"conv\":\n",
    "            self.num_channels = params[\"num_channels\"]\n",
    "            # each of the convolution layers below have the arguments (input_channels, output_channels, filter_size,\n",
    "            # stride, padding). We also include batch normalization layers that help stabilise training.\n",
    "            self.conv1 = nn.Conv2d(1, self.num_channels, 3, stride=1, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(self.num_channels)\n",
    "            self.conv2 = nn.Conv2d(self.num_channels, self.num_channels*2, 3, stride=1, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(self.num_channels*2)\n",
    "            self.conv3 = nn.Conv2d(self.num_channels*2, self.num_channels*4, 3, stride=1, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(self.num_channels*4)\n",
    "\n",
    "            # 2 fully connected layers to transform the output of the convolution layers to the final output\n",
    "            self.fc1 = nn.Linear(125*2*self.num_channels*4, self.num_channels*4)\n",
    "            self.fcbn1 = nn.BatchNorm1d(self.num_channels*4)\n",
    "            self.fc2 = nn.Linear(self.num_channels*4, 4)\n",
    "            self.dropout_rate = params[\"dropout_rate\"]\n",
    "        \n",
    "        elif self.type == \"base\":\n",
    "            # simple base model\n",
    "            self.fc_1 = nn.Linear(22 * 1000, 1000)\n",
    "            self.fc_2 = nn.Linear(1000, 30)\n",
    "            self.fc_3 = nn.Linear(30, 4)\n",
    "\n",
    "        elif self.type == \"lstm\":\n",
    "            # input_size, hidden_size, num_layers\n",
    "            self.lstm = nn.LSTM(25, 20, 2)\n",
    "            # the fully connected layer transforms the output to give the final output layer\n",
    "            self.fc = nn.Linear(20, 1)\n",
    "            if params.bidirectional == 1:\n",
    "                self.lstm = nn.LSTM(25, 20, 2, bidirectional=True)\n",
    "                self.fc = nn.Linear(40, 1)\n",
    "\n",
    "        if self.type == \"deepconv\":\n",
    "            # in_channels, out_channels, kernel_size\n",
    "            self.conv1 = nn.Conv2d(1, 25, (1,10), stride=1, padding=(0, 1))\n",
    "            self.conv2 = nn.Conv2d(25, 50, (1,10), stride=1, padding=(0, 1))\n",
    "            self.conv3 = nn.Conv2d(50, 100, (1,10), stride=1, padding=(0, 1))\n",
    "            self.conv4 = nn.Conv2d(100, 200, (1,10), stride=1, padding=(0, 1))\n",
    "            self.fc1 = nn.Linear(200*8*22, 400)\n",
    "            self.fcbn1 = nn.BatchNorm1d(400)\n",
    "            self.fc2 = nn.Linear(400, 4)\n",
    "            self.dropout_rate = params[\"dropout_rate\"]\n",
    "\n",
    "        if self.type == \"deepconv_nodo\":\n",
    "            # in_channels, out_channels, kernel_size\n",
    "            self.conv1 = nn.Conv2d(1, 25, (1,10), stride=1, padding=1)\n",
    "            self.conv2 = nn.Conv2d(25, 50, (1,10), stride=1, padding=1)\n",
    "            self.conv3 = nn.Conv2d(50, 100, (1,10), stride=1, padding=1)\n",
    "            self.conv4 = nn.Conv2d(100, 200, (1,10), stride=1, padding=1)\n",
    "            self.conv5 = nn.Conv2d(200, 400, (1,10), stride=1, padding=1)\n",
    "            self.fc1 = nn.Linear(400*4*35, 400)\n",
    "            self.fcbn1 = nn.BatchNorm1d(400)\n",
    "            self.fc2 = nn.Linear(400, 4)\n",
    "\n",
    "        if self.type == \"deeplstm\":\n",
    "            self.lstm = nn.LSTM(25, 20, 2, bidirectional=True)\n",
    "            self.fc1 = nn.Linear(40, 10)\n",
    "            self.fcbn1 = nn.BatchNorm1d(10)\n",
    "            self.fc2 = nn.Linear(10, 1)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self, s):\n",
    "        \"\"\"\n",
    "        This function defines how we use the components of our network to operate on an input batch.\n",
    "        Args:\n",
    "            s: (Variable) contains a batch of images, of dimension batch_size x 2000 x 5.\n",
    "\n",
    "        Returns:\n",
    "            out: (Variable) dimension batch_size indicating probability of a seizure.\n",
    "\n",
    "        Note: the dimensions after each step are provided\n",
    "        \"\"\"\n",
    "        if (self.type == \"reg\"):\n",
    "            s = s.view(-1, 22 * 1000)\n",
    "            s = self.fc(s)\n",
    "            return F.sigmoid(s)\n",
    "\n",
    "        if (self.type == \"conv\"):\n",
    "            # we apply the convolution layers, followed by batch normalisation, maxpool and relu x 3\n",
    "            s = s.unsqueeze(1)                             # -> batch_size x 1 x 22 x 1000\n",
    "            s = self.bn1(self.conv1(s))                    # batch_size x num_channels x 22 x 1000\n",
    "            s = F.relu(F.max_pool2d(s, 2))                 # batch_size x num_channels x 11 x 500\n",
    "            s = self.bn2(self.conv2(s))                    # batch_size x num_channels*2 x 11 x 500 \n",
    "            s = F.relu(F.max_pool2d(s, 2))                 # batch_size x num_channels*2 x 5 x 250 \n",
    "            s = self.bn3(self.conv3(s))                    # batch_size x num_channels*4 x 250 x 5\n",
    "            s = F.relu(F.max_pool2d(s, 2))                 # batch_size x num_channels*4 x 125 x 2\n",
    "\n",
    "            # flatten the output for each image\n",
    "            s = s.view(-1, 125*2*self.num_channels*4)           # batch_size x 125*2*num_channels*4\n",
    "            # apply 2 fully connected layers with dropout\n",
    "            s = F.dropout(F.relu(self.fcbn1(self.fc1(s))),\n",
    "                p=self.dropout_rate, training=self.training)    # batch_size x self.num_channels*4\n",
    "            s = self.fc2(s)                                     # batch_size x 4\n",
    "            return F.sigmoid(s)\n",
    "\n",
    "        elif (self.type == \"base\"):\n",
    "            s = s.view(-1, 22 * 1000)\n",
    "            s = F.relu(self.fc_1(s))\n",
    "            s = F.relu(self.fc_2(s))\n",
    "            s = self.fc_3(s)\n",
    "            return F.sigmoid(s)\n",
    "\n",
    "        elif (self.type == \"lstm\"):\n",
    "            s = s.transpose(0, 1)\n",
    "            # Forward propagate RNN\n",
    "            out, _ = self.lstm(s)  \n",
    "            # Decode hidden state of last time step (seq_len, batch, hidden_size * num_directions)\n",
    "            last_out = out[-1,:,:]\n",
    "            out = self.fc(last_out)  \n",
    "            return F.sigmoid(out)\n",
    "\n",
    "        elif (self.type == \"deeplstm\"):\n",
    "            s = s.transpose(0, 1)\n",
    "            # Forward propagate RNN\n",
    "            out, hidden = self.lstm(s)  \n",
    "            # Decode hidden state of last time step (seq_len, batch, hidden_size * num_directions)\n",
    "            s = F.relu(F.max_pool1d(hidden[0], 2))\n",
    "            s = s.transpose(0, 1)\n",
    "            s = s.contiguous()\n",
    "            s = s.view(-1, 4 * 10)\n",
    "            s = F.relu(self.fcbn1(self.fc1(s)))\n",
    "            s = self.fc2(s)  \n",
    "            return F.sigmoid(s)\n",
    "\n",
    "        elif (self.type == \"deepconv\"):\n",
    "            s = s.unsqueeze(1)                                   # -> batch_size x 1 x 22 x 1000\n",
    "            s = F.elu(self.conv1(s))                             # batch_size x 25 x 22 x 1000\n",
    "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 25 x 22 x 331\n",
    "            s = F.elu(self.conv2(s))                             # batch_size x 50 x 22 x 331 \n",
    "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 50 x 22 x 108 \n",
    "            s = F.elu(self.conv3(s))                             # batch_size x 100 x 22 x 108\n",
    "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 100 x 22 x 33\n",
    "            s = F.elu(self.conv4(s))                             # batch_size x 200 x 22 x 33 \n",
    "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 200 x 22 x 8 \n",
    "            s = s.contiguous()\n",
    "#             print(s.shape)\n",
    "            s = s.view(-1, 200*8*22)\n",
    "            s = F.dropout(F.relu(self.fcbn1(self.fc1(s))),p=self.dropout_rate, training=self.training)\n",
    "            s = self.fc2(s)\n",
    "            return F.sigmoid(s)\n",
    "\n",
    "        elif (self.type == \"deepconv_nodo\"):\n",
    "            s = s.unsqueeze(1)\n",
    "            s = F.relu(self.conv1(s))\n",
    "            s = F.max_pool2d(s, (3, 1))\n",
    "            s = F.relu(self.conv2(s))\n",
    "            s = F.max_pool2d(s, (3, 1))\n",
    "            s = F.relu(self.conv3(s))\n",
    "            s = F.max_pool2d(s, (3, 1))\n",
    "            s = F.relu(self.conv4(s))\n",
    "            s = F.max_pool2d(s, (3, 1))\n",
    "            s = F.relu(self.conv5(s))\n",
    "            s = F.max_pool2d(s, (3, 1))\n",
    "            s = s.contiguous()\n",
    "            s = s.view(-1, 400*4*35)\n",
    "            s = F.relu(self.fcbn1(self.fc1(s)))\n",
    "            s = self.fc2(s)\n",
    "            return F.sigmoid(s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def f1score(outputs, labels):\n",
    "#     \"\"\"\n",
    "#     Compute the f1 score, given the outputs and labels for all slices.\n",
    "\n",
    "#     Args:\n",
    "#         outputs: (np.ndarray) dimension batch_size - sigmoid output of the model\n",
    "#         labels: (np.ndarray) dimension batch_size - each element is 0 (nonseizure) or 1 (seizure)\n",
    "\n",
    "#     Returns: (float) f1 score in [0,1]\n",
    "#     \"\"\"\n",
    "#     outputs_round = np.rint(outputs)\n",
    "#     labels = labels.reshape(outputs_round.shape)\n",
    "#     numerator = np.sum(np.logical_and(outputs_round == 1, outputs_round == labels))\n",
    "#     precision_denom = max(outputs_round.sum(), 1e-8)\n",
    "#     recall_denom = max(labels.sum(), 1e-8)\n",
    "#     precision = 1.0 * numerator / precision_denom\n",
    "#     recall = 1.0 * numerator / recall_denom\n",
    "#     if (precision + recall == 0):\n",
    "#         return 0\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     # import ipdb; ipdb.set_trace()\n",
    "#     return f1\n",
    "\n",
    "\n",
    "# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\n",
    "# metrics = {\n",
    "#     'accuracy': accuracy,\n",
    "#     'f1': f1score,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the cross entropy loss given outputs and labels.\n",
    "\n",
    "    Args:\n",
    "        outputs: (Variable) dimension batch_size - output of the model\n",
    "        labels: (Variable) dimension batch_size, where each element is 0 or 1\n",
    "\n",
    "    Returns:\n",
    "        loss (Variable): cross entropy loss for all slices in the batch\n",
    "    \"\"\"\n",
    "    # ((1-labels.float()) * torch.log(1 - outputs) + labels.float() * torch.log(outputs)).mean()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "#     outputs = outputs.squeeze()\n",
    "    out = loss(outputs, labels)\n",
    "    return out\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Compute the accuracy, given the outputs and labels for all slices.\n",
    "\n",
    "    Args:\n",
    "        outputs: (np.ndarray) dimension batch_size - sigmoid output of the model\n",
    "        labels: (np.ndarray) dimension batch_size - each element is 0 (nonseizure) or 1 (seizure)\n",
    "\n",
    "    Returns: (float) accuracy in [0,1]\n",
    "    \"\"\"\n",
    "    s = torch.exp(output)\n",
    "    accuracy = (labels == s.max(dim=1)[1]).type(torch.FloatTensor).mean().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this model by yourself?\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(1, 1, [1, 10]) \n",
    "#         self.conv2 = nn.Conv1d(1, 1, [1, 10]) \n",
    "#         self.conv3 = nn.Conv1d(1, 1, [1, 10]) \n",
    "#         self.fc1 = nn.Linear(32 * 22, 64)\n",
    "#         self.fc2 = nn.Linear(64, 4)\n",
    "#         self.m1 = nn.BatchNorm2d(1)\n",
    "#         self.m2 = nn.BatchNorm2d(1)\n",
    "#         self.m3 = nn.BatchNorm2d(1)\n",
    "#         self.d1 = nn.Dropout(p=0.5)\n",
    "#         self.d2 = nn.Dropout(p=0.5)\n",
    "#         self.d3 = nn.Dropout(p=0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.max_pool2d(F.elu(self.d1(self.m1(self.conv1(x.unsqueeze(1))))), (1, 3)) # 1000 => 991 => 330\n",
    "#         x = F.max_pool2d(F.elu(self.d2(self.m2(self.conv2(x)))), (1, 3)) # 330 => 321 => 107\n",
    "#         x = F.max_pool2d(F.elu(self.d3(self.m3(self.conv3(x)))), (1, 3)) # 107 => 98 => 32\n",
    "#         x = x.view(-1, 32 * 22)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data / label into tensor\n",
    "\n",
    "x = torch.tensor(X_train_valid).float()\n",
    "y = torch.tensor(y_train_valid - 769, dtype=torch.int64)\n",
    "\n",
    "x_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(y_test - 769, dtype=torch.int64)\n",
    "\n",
    "\n",
    "# if you want onehot encode:\n",
    "\n",
    "# y_onehot = torch.FloatTensor(2115, 4)\n",
    "# y_onehot.zero_()\n",
    "# y_onehot.scatter_(1, y.view(-1, 1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process w/ Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"type\": \"conv\", \"num_channels\": 32, \"dropout_rate\": 0.8}\n",
    "params = {\"type\": \"deepconv\", \"dropout_rate\": 0.8}\n",
    "net = Net(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "  training loss: 1.2869\n",
      "  test acc: 0.3454\n",
      "epoch 10\n",
      "  training loss: 0.8139\n",
      "  test acc: 0.4199\n",
      "epoch 20\n",
      "  training loss: 0.7649\n",
      "  test acc: 0.3973\n",
      "epoch 30\n",
      "  training loss: 0.7592\n",
      "  test acc: 0.3928\n",
      "epoch 40\n",
      "  training loss: 0.7547\n",
      "  test acc: 0.3815\n",
      "epoch 50\n",
      "  training loss: 0.7537\n",
      "  test acc: 0.4063\n",
      "epoch 60\n",
      "  training loss: 0.7539\n",
      "  test acc: 0.3679\n",
      "epoch 70\n",
      "  training loss: 0.7524\n",
      "  test acc: 0.4018\n",
      "epoch 80\n",
      "  training loss: 0.7585\n",
      "  test acc: 0.3950\n",
      "epoch 90\n",
      "  training loss: 0.7504\n",
      "  test acc: 0.4289\n",
      "epoch 100\n",
      "  training loss: 0.7490\n",
      "  test acc: 0.3770\n",
      "epoch 110\n",
      "  training loss: 0.7475\n",
      "  test acc: 0.3770\n",
      "epoch 120\n",
      "  training loss: 0.7493\n",
      "  test acc: 0.4018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1412cc260802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 32\n",
    "lam = 1e-2\n",
    "print_every = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    permutation = torch.randperm(x.size()[0])\n",
    "\n",
    "    for i in range(0, x.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = x[indices], y[indices]\n",
    "\n",
    "        outputs = net.forward(batch_x)\n",
    "        loss = loss_fn(outputs, batch_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % print_every == 0:\n",
    "        print(\"epoch %d\" %epoch)\n",
    "        \n",
    "        outputs = net.forward(x)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        print(\"  training loss: %.4f\" %loss.item())\n",
    "        \n",
    "\n",
    "        output_test = net(x_test_tensor)\n",
    "        ps = torch.exp(output_test)\n",
    "        equality = (y_test_tensor.data == ps.max(dim=1)[1])\n",
    "        print(\"  test acc: %.4f\" %equality.type(torch.FloatTensor).mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 22, 1000])\n",
      "torch.Size([32, 25, 22, 331])\n",
      "torch.Size([32, 50, 22, 108])\n",
      "torch.Size([32, 100, 22, 33])\n",
      "torch.Size([32, 200, 22, 8])\n",
      "torch.Size([32, 200, 22, 8])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(1, 25, (1, 10), stride=1, padding=(0, 1))\n",
    "conv2 = nn.Conv2d(25, 50, (1, 10), stride=1, padding=(0, 1))\n",
    "conv3 = nn.Conv2d(50, 100, (1, 10), stride=1, padding=(0, 1))\n",
    "conv4 = nn.Conv2d(100, 200, (1, 10), stride=1, padding=(0, 1))\n",
    "# conv5 = nn.Conv2d(200, 400, (1, 10), stride=1, padding=(0, 1))\n",
    "fc1 = nn.Linear(400*4*22, 400)\n",
    "fcbn1 = nn.BatchNorm1d(400)\n",
    "fc2 = nn.Linear(400, 4)\n",
    "dropout_rate = params[\"dropout_rate\"]\n",
    "\n",
    "s = batch_x\n",
    "s = s.unsqueeze(1)                                   # -> batch_size x 1 x 1000 x 22\n",
    "print(s.shape)\n",
    "s = F.elu(conv1(s))                             # batch_size x 25 x 1000 x 22\n",
    "s = F.max_pool2d(s, (1, 3))      # batch_size x 25 x 334 x 22\n",
    "print(s.shape)\n",
    "s = F.elu(conv2(s))                             # batch_size x 50 x 334 x 22\n",
    "s = F.max_pool2d(s, (1, 3))                          # batch_size x 50 x 112 x 22\n",
    "print(s.shape)\n",
    "s = F.elu(conv3(s))                             # batch_size x 100 x 112 x 22\n",
    "s = F.max_pool2d(s, (1, 3))                          # batch_size x 100 x 38 x 22\n",
    "print(s.shape)\n",
    "s = F.elu(conv4(s))                             # batch_size x 200 x 38 x 22\n",
    "s = F.max_pool2d(s, (1, 3))                          # batch_size x 200 x 13 x 22\n",
    "print(s.shape)\n",
    "# s = F.elu(conv5(s))                             # batch_size x 400 x 13 x 22\n",
    "# print(s.shape)\n",
    "# s = F.max_pool2d(s, (1, 3))                          # batch_size x 400 x 4 x 22\n",
    "s = s.contiguous()\n",
    "print(s.shape)\n",
    "\n",
    "s = s.view(-1, 400*4*22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 11, 500])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = batch_x\n",
    "s = s.unsqueeze(1)                                  # -> batch_size x 1 x 1000 x 22\n",
    "s = net.bn1(net.conv1(s))\n",
    "s = F.relu(F.max_pool2d(s, 2))\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1536000 / 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=32000, out_features=128, bias=True)\n",
       "  (fcbn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=4, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28893905878067017"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final testing acc\n",
    "x_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(y_test - 769, dtype=torch.int64)\n",
    "\n",
    "output_test = net(x_test_tensor)\n",
    "ps = torch.exp(output_test)\n",
    "equality = (y_test_tensor.data == ps.max(dim=1)[1])\n",
    "equality.type(torch.FloatTensor).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best testing acc should be ~54%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
