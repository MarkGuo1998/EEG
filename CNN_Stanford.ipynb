{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CNN Stanford.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9jQl-GrSdgJ"
      },
      "source": [
        "Next step:\n",
        "\n",
        "Fix RNN\n",
        "\n",
        "Test dense networks\n",
        "\n",
        "ResNet?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juANUWN9I4c5"
      },
      "source": [
        "### Utility / Load data\n",
        "When you are running this notebook on colab - run the first 2 cells (remenber to change the path in cell 2) to mount your data to the right path, so that the notebook could locate it. \n",
        "\n",
        "If you are running this notebook on your local PC, there is no need to run the first 2 cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxZe1lCfI4-K",
        "outputId": "c63941bf-209d-4f2f-93d7-e2ab53fe69a8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09zsa41vJI0W",
        "outputId": "e98ea131-5422-4874-ead5-cca8001742d5"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/gdrive/MyDrive/EE247/')\n",
        "%cd gdrive/MyDrive/EE247"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/EE247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvpyWP8oI4c7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvBAsdQgI4c8"
      },
      "source": [
        "### Shape of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sgyxUK0I4c9",
        "outputId": "7f2022a8-dd02-454c-89f8-f4c39c0cac19"
      },
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSsohTEAI4c-"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qin6G1p1I4c-"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "a8YhCFETI4c-",
        "outputId": "3e33abb8-641e-4f2e-88c0-0bab574ed133"
      },
      "source": [
        "fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
        "# for i in range(2115):\n",
        "\n",
        "i=3\n",
        "plt.imshow(X_train_valid[i, :, :100])\n",
        "print(y_train_valid[i])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMJp1xKCI4c_"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzf_kPhVI4dA"
      },
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxFvccmqN5Mz"
      },
      "source": [
        "### Check if CUDA is avaliable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCIG9EyiLT8R",
        "outputId": "44e9fbcc-0e9d-4005-94c5-99d48948abe5"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "use_cuda"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkh7vH6EI4dA"
      },
      "source": [
        "### Model\n",
        "\n",
        "Options:\n",
        "\n",
        "\"conv\": fixed, so that the shape/dimensions match our dataset\n",
        "\n",
        "\"deepconv\": fixed\n",
        "\n",
        "\"best\": fixed (this means the best CNN model till now; probably also the best model overall)\n",
        "\n",
        "\"reg\" and \"base\": fixed, BUT I haven't tested them out\n",
        "\n",
        "other models: not fixed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5D6VhdbI4dA"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, params):\n",
        "        \"\"\"\n",
        "        We define a network based on the parameter to predict whether the slice is a seizure. The current models are:\n",
        "        - base: flatten the matrix and apply a neural net with one hidden layer\n",
        "        - conv: apply a standard vision neural net of 3 convolutional layers (filters, batch norm, pool, relu)\n",
        "                and then flatten and apply two fully connected layers with batch norm and dropout\n",
        "        - lstm: a\n",
        "\n",
        "        Args:\n",
        "            params: (Params) contains num_channels\n",
        "        \"\"\"\n",
        "        super(Net, self).__init__()\n",
        "        self.type = params[\"type\"]\n",
        "\n",
        "        if self.type == \"reg\":\n",
        "            self.fc = nn.Linear(22 * 1000, 4)\n",
        "\n",
        "        if self.type == \"conv\":\n",
        "            self.num_channels = params[\"num_channels\"]\n",
        "            # each of the convolution layers below have the arguments (input_channels, output_channels, filter_size,\n",
        "            # stride, padding). We also include batch normalization layers that help stabilise training.\n",
        "            self.conv1 = nn.Conv2d(1, self.num_channels, 3, stride=1, padding=1)\n",
        "            self.bn1 = nn.BatchNorm2d(self.num_channels)\n",
        "            self.conv2 = nn.Conv2d(self.num_channels, self.num_channels*2, 3, stride=1, padding=1)\n",
        "            self.bn2 = nn.BatchNorm2d(self.num_channels*2)\n",
        "            self.conv3 = nn.Conv2d(self.num_channels*2, self.num_channels*4, 3, stride=1, padding=1)\n",
        "            self.bn3 = nn.BatchNorm2d(self.num_channels*4)\n",
        "\n",
        "            # 2 fully connected layers to transform the output of the convolution layers to the final output\n",
        "            self.fc1 = nn.Linear(125*2*self.num_channels*4, self.num_channels*4)\n",
        "            self.fcbn1 = nn.BatchNorm1d(self.num_channels*4)\n",
        "            self.fc2 = nn.Linear(self.num_channels*4, 4)\n",
        "            self.dropout_rate = params[\"dropout_rate\"]\n",
        "        \n",
        "        elif self.type == \"base\":\n",
        "            # simple base model\n",
        "            self.fc_1 = nn.Linear(22 * 1000, 1000)\n",
        "            self.fc_2 = nn.Linear(1000, 30)\n",
        "            self.fc_3 = nn.Linear(30, 4)\n",
        "\n",
        "        elif self.type == \"lstm\":\n",
        "            # input_size, hidden_size, num_layers\n",
        "            self.lstm = nn.LSTM(22, 20, 2)\n",
        "            # the fully connected layer transforms the output to give the final output layer\n",
        "            self.fc = nn.Linear(20, 1)\n",
        "            if params.bidirectional == 1:\n",
        "                self.lstm = nn.LSTM(25, 20, 2, bidirectional=True)\n",
        "                self.fc = nn.Linear(40, 4)\n",
        "\n",
        "        if self.type == \"deepconv\":\n",
        "            # in_channels, out_channels, kernel_size\n",
        "            self.conv1 = nn.Conv2d(1, 25, (1,10), stride=1, padding=(0, 1))\n",
        "            self.conv2 = nn.Conv2d(25, 50, (1,10), stride=1, padding=(0, 1))\n",
        "            self.conv3 = nn.Conv2d(50, 100, (1,10), stride=1, padding=(0, 1))\n",
        "            self.conv4 = nn.Conv2d(100, 200, (1,10), stride=1, padding=(0, 1))\n",
        "            self.fc1 = nn.Linear(200*8*22, 400)\n",
        "            self.fcbn1 = nn.BatchNorm1d(400)\n",
        "            self.fc2 = nn.Linear(400, 4)\n",
        "            self.dropout_rate = params[\"dropout_rate\"]\n",
        "\n",
        "        if self.type == \"deepconv_nodo\":\n",
        "            # in_channels, out_channels, kernel_size\n",
        "            self.conv1 = nn.Conv2d(1, 25, (1,10), stride=1, padding=(0, 1))\n",
        "            self.conv2 = nn.Conv2d(25, 50, (1,10), stride=1, padding=(0, 1))\n",
        "            self.conv3 = nn.Conv2d(50, 100, (1,10), stride=1, padding=(0, 1))\n",
        "            self.conv4 = nn.Conv2d(100, 200, (1,10), stride=1, padding=(0, 1))\n",
        "            self.fc1 = nn.Linear(200*8*22, 400)\n",
        "            self.fcbn1 = nn.BatchNorm1d(400)\n",
        "            self.fc2 = nn.Linear(400, 4)\n",
        "\n",
        "        if self.type == \"deeplstm\":\n",
        "            self.lstm = nn.LSTM(25, 20, 2, bidirectional=True)\n",
        "            self.fc1 = nn.Linear(40, 10)\n",
        "            self.fcbn1 = nn.BatchNorm1d(10)\n",
        "            self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "        if self.type == \"best\":\n",
        "            self.conv1 = nn.Conv1d(1, 1, [1, 10]) \n",
        "            self.conv2 = nn.Conv1d(1, 1, [1, 10]) \n",
        "            self.conv3 = nn.Conv1d(1, 1, [1, 10]) \n",
        "            self.fc2 = nn.Linear(32*22, 4)\n",
        "            self.m1 = nn.BatchNorm2d(1)\n",
        "            self.m2 = nn.BatchNorm2d(1)\n",
        "            self.m3 = nn.BatchNorm2d(1)\n",
        "            \n",
        "\n",
        "    def forward(self, s):\n",
        "        \"\"\"\n",
        "        This function defines how we use the components of our network to operate on an input batch.\n",
        "        Args:\n",
        "            s: (Variable) contains a batch of images, of dimension batch_size x 2000 x 5.\n",
        "\n",
        "        Returns:\n",
        "            out: (Variable) dimension batch_size indicating probability of a seizure.\n",
        "\n",
        "        Note: the dimensions after each step are provided\n",
        "        \"\"\"\n",
        "        if (self.type == \"reg\"):\n",
        "            s = s.view(-1, 22 * 1000)\n",
        "            s = self.fc(s)\n",
        "            return s\n",
        "\n",
        "        if (self.type == \"conv\"):\n",
        "            # we apply the convolution layers, followed by batch normalisation, maxpool and relu x 3\n",
        "            s = s.unsqueeze(1)                             # -> batch_size x 1 x 22 x 1000\n",
        "            s = self.bn1(self.conv1(s))                    # batch_size x num_channels x 22 x 1000\n",
        "            s = F.relu(F.max_pool2d(s, 2))                 # batch_size x num_channels x 11 x 500\n",
        "            s = self.bn2(self.conv2(s))                    # batch_size x num_channels*2 x 11 x 500 \n",
        "            s = F.relu(F.max_pool2d(s, 2))                 # batch_size x num_channels*2 x 5 x 250 \n",
        "            s = self.bn3(self.conv3(s))                    # batch_size x num_channels*4 x 250 x 5\n",
        "            s = F.relu(F.max_pool2d(s, 2))                 # batch_size x num_channels*4 x 125 x 2\n",
        "\n",
        "            # flatten the output for each image\n",
        "            s = s.view(-1, 125*2*self.num_channels*4)           # batch_size x 125*2*num_channels*4\n",
        "            # apply 2 fully connected layers with dropout\n",
        "            s = F.dropout(F.relu(self.fcbn1(self.fc1(s))),\n",
        "                p=self.dropout_rate, training=self.training)    # batch_size x self.num_channels*4\n",
        "            s = self.fc2(s)                                     # batch_size x 4\n",
        "            return s\n",
        "\n",
        "        elif (self.type == \"base\"):\n",
        "            s = s.view(-1, 22 * 1000)\n",
        "            s = F.relu(self.fc_1(s))\n",
        "            s = F.relu(self.fc_2(s))\n",
        "            s = self.fc_3(s)\n",
        "            return s\n",
        "\n",
        "        elif (self.type == \"lstm\"):\n",
        "            s = s.transpose(0, 1)\n",
        "            # Forward propagate RNN\n",
        "            out, _ = self.lstm(s)  \n",
        "            # Decode hidden state of last time step (seq_len, batch, hidden_size * num_directions)\n",
        "            last_out = out[-1,:,:]\n",
        "            out = self.fc(last_out)  \n",
        "            return F.sigmoid(out)\n",
        "\n",
        "        elif (self.type == \"deeplstm\"):\n",
        "            s = s.transpose(0, 1)\n",
        "            # Forward propagate RNN\n",
        "            out, hidden = self.lstm(s)  \n",
        "            # Decode hidden state of last time step (seq_len, batch, hidden_size * num_directions)\n",
        "            s = F.relu(F.max_pool1d(hidden[0], 2))\n",
        "            s = s.transpose(0, 1)\n",
        "            s = s.contiguous()\n",
        "            s = s.view(-1, 4 * 10)\n",
        "            s = F.relu(self.fcbn1(self.fc1(s)))\n",
        "            s = self.fc2(s)  \n",
        "            return F.sigmoid(s)\n",
        "\n",
        "        elif (self.type == \"deepconv\"):\n",
        "            s = s.unsqueeze(1)                                   # -> batch_size x 1 x 22 x 1000\n",
        "            s = F.elu(self.conv1(s))                             # batch_size x 25 x 22 x 1000\n",
        "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 25 x 22 x 331\n",
        "            s = F.elu(self.conv2(s))                             # batch_size x 50 x 22 x 331 \n",
        "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 50 x 22 x 108 \n",
        "            s = F.elu(self.conv3(s))                             # batch_size x 100 x 22 x 108\n",
        "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 100 x 22 x 33\n",
        "            s = F.elu(self.conv4(s))                             # batch_size x 200 x 22 x 33 \n",
        "            s = F.max_pool2d(s, (1, 3))                          # batch_size x 200 x 22 x 8 \n",
        "            s = s.contiguous()\n",
        "#             print(s.shape)\n",
        "            s = s.view(-1, 200*8*22)\n",
        "            s = F.dropout(F.relu(self.fcbn1(self.fc1(s))),p=self.dropout_rate, training=self.training)\n",
        "            s = self.fc2(s)\n",
        "            return s\n",
        "\n",
        "        elif (self.type == \"deepconv_nodo\"):\n",
        "            s = s.unsqueeze(1)\n",
        "            s = F.relu(self.conv1(s))\n",
        "            s = F.max_pool2d(s, (1, 3))\n",
        "            s = F.relu(self.conv2(s))\n",
        "            s = F.max_pool2d(s, (1, 3))\n",
        "            s = F.relu(self.conv3(s))\n",
        "            s = F.max_pool2d(s, (1, 3))\n",
        "            s = F.relu(self.conv4(s))\n",
        "            s = F.max_pool2d(s, (1, 3))\n",
        "            s = s.contiguous()\n",
        "            s = s.view(-1, 200*8*22)\n",
        "            s = F.relu(self.fcbn1(self.fc1(s)))\n",
        "            s = self.fc2(s)\n",
        "            return s\n",
        "\n",
        "        elif self.type == \"best\":\n",
        "            s = s.unsqueeze(1)\n",
        "            s = F.max_pool2d(F.elu(self.conv1(self.m1(s))), (1, 3)) # 1000 => 991 => 330\n",
        "            s = F.max_pool2d(F.elu(self.conv2(self.m2(s))), (1, 3)) # 330 => 321 => 107\n",
        "            s = F.max_pool2d(F.elu(self.conv3(self.m3(s))), (1, 3)) # 107 => 98 => 32\n",
        "            s = s.view(-1, 32 * 22)\n",
        "            s = self.fc2(s)\n",
        "            return s\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def f1score(outputs, labels):\n",
        "#     \"\"\"\n",
        "#     Compute the f1 score, given the outputs and labels for all slices.\n",
        "\n",
        "#     Args:\n",
        "#         outputs: (np.ndarray) dimension batch_size - sigmoid output of the model\n",
        "#         labels: (np.ndarray) dimension batch_size - each element is 0 (nonseizure) or 1 (seizure)\n",
        "\n",
        "#     Returns: (float) f1 score in [0,1]\n",
        "#     \"\"\"\n",
        "#     outputs_round = np.rint(outputs)\n",
        "#     labels = labels.reshape(outputs_round.shape)\n",
        "#     numerator = np.sum(np.logical_and(outputs_round == 1, outputs_round == labels))\n",
        "#     precision_denom = max(outputs_round.sum(), 1e-8)\n",
        "#     recall_denom = max(labels.sum(), 1e-8)\n",
        "#     precision = 1.0 * numerator / precision_denom\n",
        "#     recall = 1.0 * numerator / recall_denom\n",
        "#     if (precision + recall == 0):\n",
        "#         return 0\n",
        "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
        "#     # import ipdb; ipdb.set_trace()\n",
        "#     return f1\n",
        "\n",
        "\n",
        "# maintain all metrics required in this dictionary- these are used in the training and evaluation loops\n",
        "# metrics = {\n",
        "#     'accuracy': accuracy,\n",
        "#     'f1': f1score,\n",
        "# }"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8VykA0O1sE"
      },
      "source": [
        "Definition of 2 methods: loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcv_-qaVI4dB"
      },
      "source": [
        "def loss_fn(outputs, labels):\n",
        "    \"\"\"\n",
        "    Compute the cross entropy loss given outputs and labels.\n",
        "\n",
        "    Args:\n",
        "        outputs: (Variable) dimension batch_size - output of the model\n",
        "        labels: (Variable) dimension batch_size, where each element is 0 or 1\n",
        "\n",
        "    Returns:\n",
        "        loss (Variable): cross entropy loss for all slices in the batch\n",
        "    \"\"\"\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    out = loss(outputs, labels)\n",
        "    return out\n",
        "\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    \"\"\"\n",
        "    Compute the accuracy, given the outputs and labels for all slices.\n",
        "\n",
        "    Args:\n",
        "        outputs: (Variable) dimension batch_size - sigmoid output of the model\n",
        "        labels: (Variable) dimension batch_size - each element is 0 (nonseizure) or 1 (seizure)\n",
        "\n",
        "    Returns: (float) accuracy in [0,1]\n",
        "    \"\"\"\n",
        "    s = torch.exp(outputs)\n",
        "    accuracy = (labels == s.max(dim=1)[1]).type(torch.FloatTensor).mean().item()\n",
        "    return accuracy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mFon651I4dC"
      },
      "source": [
        "# change data / label into tensor\n",
        "\n",
        "x = torch.tensor(X_train_valid).float()\n",
        "y = torch.tensor(y_train_valid - 769, dtype=torch.int64)\n",
        "\n",
        "x_test_tensor = torch.tensor(X_test).float()\n",
        "y_test_tensor = torch.tensor(y_test - 769, dtype=torch.int64)\n",
        "\n",
        "\n",
        "# if you want onehot encode:\n",
        "\n",
        "# y_onehot = torch.FloatTensor(2115, 4)\n",
        "# y_onehot.zero_()\n",
        "# y_onehot.scatter_(1, y.view(-1, 1), 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDxqGuivI4dD"
      },
      "source": [
        "### Training process w/ Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5rdfNnhI4dD"
      },
      "source": [
        "# params = {\"type\": \"conv\", \"num_channels\": 32, \"dropout_rate\": 0.8}\n",
        "# params = {\"type\": \"deepconv\", \"dropout_rate\": 0.5}\n",
        "params = {\"type\": \"best\"}\n",
        "\n",
        "if use_cuda:\n",
        "  net = Net(params).cuda()\n",
        "else:\n",
        "  net = Net(params)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CEFjxjQRBSv"
      },
      "source": [
        "With deeper Conv network you should set learning rate ~ $10^{-5}$. With shallow network (like the \"*best*\" network), it could be higher like $10^{-4}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkYtZMaNI4dD",
        "outputId": "d3cd219f-1bcd-45a0-9431-d41ac752a72b"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=1.5e-4)\n",
        "\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 15 # Note that 2115 = 31 * 70\n",
        "lam = 1e-2\n",
        "print_every = 10\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if use_cuda:\n",
        "    x_test_tensor = x_test_tensor.cuda()\n",
        "    y_test_tensor = y_test_tensor.cuda()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    permutation = torch.randperm(x.size()[0])\n",
        "    for i in range(0, x.size()[0], batch_size):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = x[indices], y[indices]\n",
        "\n",
        "        if use_cuda:\n",
        "          batch_x = batch_x.cuda()\n",
        "          batch_y = batch_y.cuda()\n",
        "\n",
        "        outputs = net.forward(batch_x)\n",
        "        loss = loss_fn(outputs, batch_y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if epoch % print_every == 0:\n",
        "        print(\"epoch %d,  batch loss: %.4f\" %(epoch, loss))\n",
        "\n",
        "        output_test = net(x_test_tensor)\n",
        "        acc = accuracy(output_test, y_test_tensor)\n",
        "        print(\"  test acc: %.4f\" %acc)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0,  batch loss: 1.3085\n",
            "  test acc: 0.3115\n",
            "epoch 10,  batch loss: 1.1277\n",
            "  test acc: 0.4108\n",
            "epoch 20,  batch loss: 1.1945\n",
            "  test acc: 0.4515\n",
            "epoch 30,  batch loss: 1.1657\n",
            "  test acc: 0.5079\n",
            "epoch 40,  batch loss: 1.1735\n",
            "  test acc: 0.5102\n",
            "epoch 50,  batch loss: 0.8154\n",
            "  test acc: 0.5282\n",
            "epoch 60,  batch loss: 0.5579\n",
            "  test acc: 0.5260\n",
            "epoch 70,  batch loss: 0.7379\n",
            "  test acc: 0.5034\n",
            "epoch 80,  batch loss: 0.7986\n",
            "  test acc: 0.5485\n",
            "epoch 90,  batch loss: 0.6794\n",
            "  test acc: 0.5372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-QwueLCI4dH",
        "outputId": "6cfc010c-6fe6-4c0d-a4ed-2fe0fb897408"
      },
      "source": [
        "if use_cuda:\n",
        "  x_test_tensor = x_test_tensor.cuda()\n",
        "  y_test_tensor = y_test_tensor.cuda()\n",
        "\n",
        "output_test = net(x_test_tensor)\n",
        "acc = accuracy(output_test, y_test_tensor)\n",
        "print(\"  test acc: %.4f\" %acc)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  test acc: 0.5418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALGly6TwI4dI"
      },
      "source": [
        "best testing acc should be ~54%"
      ]
    }
  ]
}